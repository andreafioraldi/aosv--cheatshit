===================
Interrupts and time
===================

1) Realtime OS
--------------

Soft real-time and hard-realtime.
Hard realtime must have a very low error on time. For instance a car have a
real time OS.

Linux is not considered a real-time OS.

2) IDT and GDT
--------------

In Interrupt Descriptor Table we map a selector to an offset.
The selector pick a segment descriptor in GDT. Adding offset to the base of
this segment descripor points to the interrupt handler.
IDTR and GDTR are per-CPU registers.

On IDT entries, the type classify the trap associated.

Look at the idt_bits and gate_struct on Linux. On the entry there is specified
also the DPL and the Interrupt Stack Table (IST).

When receiving interrupts in user mode we want to transition to kernel space.
Use gate to set priviledge.

3) IDT Entry Initialization
---------------------------

pack_gate() takes parameters for you and fills the gate entry.

Parameters are: gate_desc*, type, func, dpl, ist, seg.

Executing pack_gate directly on IDT entry will cause a crash.
This function execute many instructions, so the way is:

 - Clone IDT entry
 - Operate on the clone
 - Store the clone on the IDT entry (one onstruction, not many)

4) Entries types
----------------

256 possible entries. Each entry is common called vector.

 - 0-19 not maskable interrupts and exceptions (even with IF=0)
 - 20-31 reserved
 - 32-127 IRQs
 - 128 syscalls
 - 129-238 IRQs
 - 239 local APIC timer interrupt
 - 240-250 reserved for future
 - 251-255 interprocessor interrupts

 Each LAPIC is a interrupt dipatcher and has its time.

5) Gate descriptor
------------------

It is basically a segment descriptor with 4 types:

 - call-gate:
      Register a function pointer that is a cross ring call specifying the
      number of arguments (those arguments are pushed on the source ring stack
      and the firmware copy them to the new stack). There is not an OS using it.
 
 - interrupt-gate
 - trap-gate
 
 - task-gate:
      Made to jump to the scheduler. With NT (Next Task) flag a task can yield
      explicetely the cpu to a different task. This lives on TSS an no one is
      using this.

6) Interrupts VS Traps
----------------------

Async events are interrupts. Can be generated by devices and some of them can be
masked or not (NMI).

Trap (or exceptions) are synchronous strictly related to the CPU exection.

Using interrupt gates you are telling the firmware to clear the interrupt
flag (IF). With a trap gate this is not done.
Critical section in a trap handler must explicitly use cli/sti but on multi core
this may not be enaugh to guarantee atomicity so the kernel uses spinlocks.

7) Global activation scheme
---------------------------

When receveing an interrupt a very simple stub is activated. It pushes on the
stack a code used by the dispatcher to know where to jump (error code).
Then jump to the handler second stub.

Traps goes directly to handler (vector number pushed by firmware).

If the IDT has an IST value that is not 0 the corresponding stack is taken from
TSS and used, otherwise is used the stack of the destination ring.

x86 interrupt frame (RSP):
  - error code/vector
  - RIP
  - CS
  - FLAGS
  - SP
  - SS

The handler makes uniform this frame (align stack in case of IRQ etc.)

Then the dispatcher is called. It firstly change GS to the value needed in
kernel space if the interrupt comes from user space (per CPU vars).

Push the content of the context on pt_regs.

Then activate the proper handler.

The handler returns to the dispatcher that do cleanup and calls iret.

swapgs instruction swap GS if coming from userpace. It relies on another MSR.
The other incarnation of GS is GSMSR and swapgs exchange those two regs.

User space provenience can be seen using the CPL in the CS on stack.

An exception example is the page fault handler that calls into do_page_fault.

8) Do page fault
----------------

In kernel mode, to validate the access to user mode pointer, the verify_area()
or access_ok() routines must be used. This can take a lot of time and happens
very often.

To do this in an efficent way Linux exploits the MMU, if an unvalid pointer
is accesses a page fault is raised.

The firmaware stores in CR2 the address that generates the fault.

Fault type in error code. The instruction address that generated the fault can
be easily taken from RSP (pushed RIP).

In copy_from_user if passed a wrong address the kernel generates a page fault.
Otherwise access checking would be costly.

Do page fault does many thigs, for example if the address is in the target
address space but it is swapped the page is reded in RAM. For not recoverable
errors a jump to bad_area() activates a fixup.

The pieces of the kernel that are allowed to crash uses code in a special
section .fixup to recover (e.g. in copy_from_user readed bytes are set to 0).

Pieces in .fixup rejumps to .text.

__ex_table is a section used to map text and fixup addresses
(instructions that may generate a fault -> associated fixup stub).

In 64 bits this changed cause expand the table to handle 64 bit pointer is
not a good idea. Offset from the current location (32 bits) are used to index
the __ex_table in x86_64.

9) Multi Core
-------------

On a single core the hardware is time shared across threads and this ensure
consistency of interrupts/traps.

On multi-core, interrupts are delivered to a single core but other core may run
another thread of the same application.

This may lead to race conditions.

Also sync code in userspace like VDSO is affected.

Memory unmapping is an example, a portion of the address space if teared down.
The kernel code has to flush a part of TLB also. The thread that called munmap
see a consistent state thanks to the TLB update and this is also true for all
the other threads on the same core.

But if a thread of the same process is on another core? The hardware state is
inconsistent! The unammped page is still cached on TLB of such core.

10) Inter Processor Interrupts
------------------------------

Generated by software. They are synchronous for the sender core and asynchronous
for the receiver core.
With this mechanism a core can trigger a state change in another core.
There are at least 2 priority levels, high or low.
Low priority are generally enqueued and then sended in batch.

IPI are an interface to APIC/LAPIC circuitry.
IPI requests go along a dedicated APIC bus (QuickPath on modern Intels).

In Linux high priority are used in critical situation like for sending halt
after a panic on a core.

There are only 4 avaiable vectors.
A dedicated vector is for flushing the TLB only (0xfd).
Via CALL_FUNCTION_VECTOR is general purpose that calls a function pointer
on the another core.

11) IPI API
-----------

Defined in struct ipi.

There is a way to register an IPI function (this is needed cause there is
only CALL_FUNCTION_VECTOR).

In old kernel there was a global struct under locks.
In 5.0 there is a per-CPU lock-free linked list.

Old steps are:

  - Lock
  - Set global function pointer
  - Set a global pointer as argument to the function
  - Send IPI
  - Other core copies function pointer and arg pointer to local variables
  - Other core unlock

This does not scale. The lock-free is a better solution:

A CPU adds an element (function + argument) to all the per-CPU lists
(struct call_single_data_t) of the other cores (yes, a bit spooky) and the
trigger the IPI.

Note: Remeber lock-free lists use CAS for insertion.

smp_call_function_many() is used to call functions on many cores.
It uses a bitmask to specify the target cores. Preemption must be disabled.

Basically, for each cpu in the mask take the per-CPU csd (the list) and add an
element with the function and the arguments. Then send IPI and at the end.
If wait is specified, wait for the completion flag in the csd of each core.

When interrupts are disabled this function can cause deadlock!

If two cores send IPI to each other and waits until completion both are waiting
for completion and does not respond to the request.

12) I/O Interrupt Management
----------------------------

Action taken when handling an interrupt are splitted across:

 - Critical Actions: IF=0, ack the interrupt, reprogram the device, exchange
   data with the device etc..

 - Non-Critial Actions: IF=1, quick data structures management (data not shared
   with device).

 - Non-Critical Deferrable Actions: eventually done. Anything else (e.g. copy
   data to userspace).

Interrupt service routines are the driver entry points and end with iret.

The same IRQ can be shared by multiple devices. Multiple ISR for an IRQ.
The hardware geometry allows ISR to find out the correct routine.

In IRQ management dispatcher we use another stack if coming from userspace.
swapgs and do this shit:

We move off the initial part (the critical) to another stack
(a stack for each cpu).

mov %rsp, %rdi
mov PER_CPU_VAR(cpu_current_top_of_stack), %rsp

Then copy the interrupt frame from old stack to the new (rdi is also saved).

pushq 0x38(%rdi)
...

This is a memory-to-memory instruction. Yes, x86 is x86.

Then, begin the common code also if coming from kernel space:

Save the registers and call do_IRQ(interrupt number). The interrupt number can
be found at the top of the stack cause it is pushed by the intitial stub.

Interrupts are offs, do_IRQ performs the critical actions.

13) Deferred work
-----------------

Work from interrupts shifted in time, must be handled carefully to not
introduce starvation.

Those events can be aggregated.
This reconciliation points can be also specified.

The initial idea was to avoid to process interrupts during a critical section
that some worker locked before the arriving of interrupts.
This satisfy a soft real-time constraint.

Top half is the not critical action that is needed to finalize the interrupt.
Bottom half is the deferrable work, top half schedule it in a proper data
structure.

Deferred work is executed in the same CPU of the top half. Probably the
reconcilition point is not to too time after the top half so this choice
exploits the cache.

14) SoftIRQs
------------

 - Fired at reconciliation points
    - Coming back from hard IRQ (IF=1)
    - Coming back from system call
    - Specified points
 - Interruptible (so reentrant)
 - Rarely used directly

Tasklets are used to not trigger soft IRQ indirectly, otherwise there will be a
considerable performance loss.

To trigger them there is a per-CPU bitmap that set if there is a pending
softIRQ. irq_stat[cpu].__softirq_pending.

In each CPU there is also a low priority thread that check, when scheduled, if
there are entries set in this bitmap.

The classes that can be setted in the bitmap are 9. For example there is the
entry for block devices. The top half register the bottom half here.

There is also the network entry and the timer.

The tasklets entry is general purpose.

__do_softIRQ() this function activates functions that have bit enabled in the
pending mask.

This switches to private stack and save a copy of the bitmap (and using those
copy). This small init work is done with IF=0 and then IF is re-enabled.
This allows new top half to register new bottom half while processing old
bottom halves.

The duration of that routine can be long. To avoid to finish the time windows,
not all bottom halves are processed but they are left to the low-priority
deamon.

A tasklet is executed once, but in the handler you can re-eanble it.

Synchronizing tasklets registered by 2 cpu can be a pain, so the kernel enforce
not concurrent execution of tasklets.

Tasklets run with preemption disabled so you cannot call functions that can
lead to sleep.

I you want to do this, use the work queue. This works can be executed later.
Similar to tasklets but without nesting. A pool of threads will execute them.

15) Timekeeping
---------------

Multiple way to keep track of time via software and hardware with different
granularity.

 - Timeouts: used mainly by networking to detect when an event does not occurs
   as excepted. Require low resolution. The average case is that they are
   removed and does not expire.

 - Timers: sequence ongoing events. Usually needs high resolution.

Hardware Clock Sources:

 - Real Time CLock (RTC), avaiable in all PCs.
 
 - Time Stamp Counter (TSC), uses cpu clock, a monotonic counter that can't be
   used for time. rdtsc x86 instruction. (this shit can overflow!)

 - Programmable Interval Timer (PIT), programmable laps, send interrupts.
 
 - CPU Local Time (LAPIC), delivers interrupt only to the local CPU.
 
 - High Precision Event Timer (HPET), multiple timers that can be used
   independently.

Clock events are abstraction introduced in 2.6.
Those events are generated from Clock Event Devices. Those Devices are
programmable and the kernel will choose the best harware support avaiable that
can generate the event.
Portability suffer for this, the same code can be less accurate in different
machines.

I the global variable jiffies keeps the number of ticks since startup.

Timer Interrupts are top/bottom half.

Top half:
  - Register bottom half
  - Increment jiffies
  - Check if the scheduler needs to be activated and then set need_resched = 1

Bottom half:
  - While need_resched call the scheduler

All these parts can produce delays. High resolution timers uses ktime_t type
that has a nanoseconds scalar representation instead of jiffies.

ktime_t can guarantee a lower bound but not hard real-time.

hrtimer struct and related APIs are used to do this.

Dynamic kernel timers are in timer_list. All functions in the list will be 
triggered at expire. Based on jiffies.

Releasing resourcing in a function called from a dynamic kernel timers must be
a careful operation.
Timers must be deleted before releasing resources, they are prone to race
conditions.

In the Timer Wheel is the place were we register multiple timer_list.
This is a multilevel priority queue.

The problem is that you do not have guarantees on unlink and placing events.
This is linear for the bucket and this is a problem.
Two different balancing operation can take different time on different levels.

Since kernel 2.6 Linux started relying on LAPIC timer. This immediately ack the
IRQ and then call local_apic_timer_interrupt().

16) Watchdogs
-------------

A component that monitors a system for "normal" beahviour and in case of
failure it perfroms a reset in order to recover normal operation.
This allows remotely log after a restart and do not lose machine that are not
recheable phisically.

In Linux a watchdog is implemented in 2 parts:

 - A module that is able to do hard reset
 - An userpace application

/dev/watchdog is used to notify the kernel module that the application is
still alive (done periodically).

The kernel device use NMI to check the counter that counts the notification
from user space and then if it is too old hard reset the machine.
